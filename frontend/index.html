<!DOCTYPE html>
<html>
<head>
  <title>Exam Proctoring Client</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <style>
    body { display: flex; flex-direction: column; align-items: center; }
    canvas, video { border: 1px solid black; margin: 5px; }
  </style>
</head>
<body>
  <h2>Exam Proctoring Client — Head Pose Demo</h2>
  <video id="input_video" width="640" height="480" autoplay muted></video>
  <canvas id="output_canvas" width="640" height="480"></canvas>

  <script>
    let cvReady = false;
    let modelPoints, cameraMatrix, distCoeffs;
    let lastFacePosition = null;
    let facePositionThreshold = 50; // pixels

    function onOpenCvReady() {
      console.log('OpenCV.js is ready!');
      cvReady = true;
    }

    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');

    let lastReportTimes = {};
    function reportEvent(eventType, details = {}, cooldown = 1000) {
      const now = Date.now();
      const last = lastReportTimes[eventType];
      const diff = now - (last || 0);

      console.log(`[reportEvent] Check: "${eventType}" | Last: ${last}, Now: ${now}, Diff: ${diff}`);

      if (!last || diff > cooldown) {
        console.log(`[reportEvent] >>> Reporting "${eventType}"`, details);
        lastReportTimes[eventType] = now;

        fetch('https://exam-proctor-client.onrender.com/report-event', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            eventType,
            details,
            timestamp: now
          })
        }).catch(err => console.error(`[reportEvent] Fetch failed:`, err));
      } else {
        console.log(`[reportEvent] Skipped (cooldown not met)`);
      }
    }

    function waitForCvReady() {
      return new Promise(resolve => {
        if (cvReady) resolve();
        else {
          let interval = setInterval(() => {
            if (cvReady) {
              clearInterval(interval);
              resolve();
            }
          }, 100);
        }
      });
    }

    waitForCvReady().then(() => {
      modelPoints = cv.matFromArray(6, 3, cv.CV_64FC1, [
        0.0, 0.0, 0.0,        // Nose tip
        0.0, -63.6, -12.5,    // Chin
        -43.3, 32.7, -26.0,   // Left eye left corner
        43.3, 32.7, -26.0,    // Right eye right corner
        -28.9, -28.9, -20.0,  // Left Mouth corner
        28.9, -28.9, -20.0    // Right mouth corner
      ]);

      const focal_length = 640;
      const center = [canvasElement.width / 2, canvasElement.height / 2];
      cameraMatrix = cv.matFromArray(3, 3, cv.CV_64FC1, [
        focal_length, 0, center[0],
        0, focal_length, center[1],
        0, 0, 1
      ]);
      distCoeffs = cv.Mat.zeros(5, 1, cv.CV_64FC1);

      const faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });

      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });

      faceMesh.onResults(onResults);

      const camera = new Camera(videoElement, {
        onFrame: async () => {
          await faceMesh.send({ image: videoElement });
        },
        width: 640,
        height: 480
      });
      camera.start();

      function onResults(results) {
        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
          const landmarks = results.multiFaceLandmarks[0];

          const nose = landmarks[1];
          const faceCenter = {
            x: nose.x * canvasElement.width,
            y: nose.y * canvasElement.height
          };

          let faceMoved = false;
          if (lastFacePosition) {
            const dx = faceCenter.x - lastFacePosition.x;
            const dy = faceCenter.y - lastFacePosition.y;
            const dist = Math.sqrt(dx * dx + dy * dy);
            faceMoved = dist > facePositionThreshold;
          }
          lastFacePosition = faceCenter;

          const imagePoints = cv.matFromArray(6, 2, cv.CV_64FC1, [
            landmarks[1].x * canvasElement.width, landmarks[1].y * canvasElement.height,
            landmarks[152].x * canvasElement.width, landmarks[152].y * canvasElement.height,
            landmarks[263].x * canvasElement.width, landmarks[263].y * canvasElement.height,
            landmarks[33].x * canvasElement.width, landmarks[33].y * canvasElement.height,
            landmarks[61].x * canvasElement.width, landmarks[61].y * canvasElement.height,
            landmarks[291].x * canvasElement.width, landmarks[291].y * canvasElement.height
          ]);

          let rvec = new cv.Mat();
          let tvec = new cv.Mat();
          let success = cv.solvePnP(modelPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec);

          if (success) {
            let rmat = new cv.Mat();
            cv.Rodrigues(rvec, rmat);

            let sy = Math.sqrt(rmat.doubleAt(0, 0) ** 2 + rmat.doubleAt(1, 0) ** 2);
            let singular = sy < 1e-6;
            let x, y, z;
            if (!singular) {
              x = Math.atan2(rmat.doubleAt(2, 1), rmat.doubleAt(2, 2));
              y = Math.atan2(-rmat.doubleAt(2, 0), sy);
              z = Math.atan2(rmat.doubleAt(1, 0), rmat.doubleAt(0, 0));
            } else {
              x = Math.atan2(-rmat.doubleAt(1, 2), rmat.doubleAt(1, 1));
              y = Math.atan2(-rmat.doubleAt(2, 0), sy);
              z = 0;
            }

            let pitch = x * 180 / Math.PI;
            let yaw = y * 180 / Math.PI;
            let roll = z * 180 / Math.PI;

            // Normalize roll
            if (roll > 90) roll -= 180;
            if (roll < -90) roll += 180;

            canvasCtx.fillStyle = "yellow";
            canvasCtx.font = "18px Arial";
            canvasCtx.fillText(`Pitch: ${pitch.toFixed(1)}°`, 10, 20);
            canvasCtx.fillText(`Yaw: ${yaw.toFixed(1)}°`, 10, 40);
            canvasCtx.fillText(`Roll: ${roll.toFixed(1)}°`, 10, 60);

            console.log("[poseCheck]", { faceMoved, yaw, pitch });

            if (!faceMoved) {
              if (Math.abs(yaw) > 30) {
                console.log("→ Trigger: head_turned");
                reportEvent('head_turned', { yaw: yaw.toFixed(1) }, 1000);
              }

              if (pitch < -20) {
                console.log("→ Trigger: head_down");
                reportEvent('head_down', { pitch: pitch.toFixed(1) }, 1000);
              }

              if (pitch > 20) {
                console.log("→ Trigger: head_up");
                reportEvent('head_up', { pitch: pitch.toFixed(1) }, 1000);
              }
            } else {
              console.log("[poseCheck] Skipped due to face movement");
            }

            drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, { color: '#6fa8dc', lineWidth: 1 });
            drawLandmarks(canvasCtx, landmarks, { color: '#FF3030', lineWidth: 1 });

            drawAxis(rvec, tvec, cameraMatrix, distCoeffs);
            rmat.delete();
          }
          rvec.delete();
          tvec.delete();
          imagePoints.delete();
        } else {
          console.log("[poseCheck] No face detected — reporting face_missing");
          reportEvent('face_missing');
        }
        canvasCtx.restore();
      }

      function drawAxis(rvec, tvec, cameraMatrix, distCoeffs) {
        const axisLength = 50;
        let axisPoints = cv.matFromArray(4, 3, cv.CV_64FC1, [
          0, 0, 0,
          axisLength, 0, 0,
          0, axisLength, 0,
          0, 0, axisLength
        ]);

        let imagePoints = new cv.Mat();
        cv.projectPoints(axisPoints, rvec, tvec, cameraMatrix, distCoeffs, imagePoints);

        const origin = { x: imagePoints.data64F[0], y: imagePoints.data64F[1] };
        const xAxis = { x: imagePoints.data64F[2], y: imagePoints.data64F[3] };
        const yAxis = { x: imagePoints.data64F[4], y: imagePoints.data64F[5] };
        const zAxis = { x: imagePoints.data64F[6], y: imagePoints.data64F[7] };

        canvasCtx.strokeStyle = "white";
        canvasCtx.beginPath(); canvasCtx.moveTo(origin.x, origin.y); canvasCtx.lineTo(xAxis.x, xAxis.y); canvasCtx.stroke();
        canvasCtx.strokeStyle = "green";
        canvasCtx.beginPath(); canvasCtx.moveTo(origin.x, origin.y); canvasCtx.lineTo(yAxis.x, yAxis.y); canvasCtx.stroke();
        canvasCtx.strokeStyle = "blue";
        canvasCtx.beginPath(); canvasCtx.moveTo(origin.x, origin.y); canvasCtx.lineTo(zAxis.x, zAxis.y); canvasCtx.stroke();

        axisPoints.delete();
        imagePoints.delete();
      }
    });
  </script>
</body>
</html>
